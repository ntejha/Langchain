{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Chatbot\n",
    "\n",
    "In this video, we'll go over an example of how to design and implement and LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions interactions.\n",
    "\n",
    "Note that this chatbot that will only use the language model to have a converstation. THere are several other related concepts that you may be looking for :\n",
    "\n",
    "- Conversational RAG : Enable a chatbot experience over an exteral source of data\n",
    "- Agents : Build a chatbot that can take actions \n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Tejha, and you said you are the president!  \\n\\nIs there anything else you'd like to tell me about your role as president?  What kind of things do you do as president? ðŸ˜Š  \\n\", response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 77, 'total_tokens': 129, 'completion_time': 0.106850082, 'prompt_time': 0.005288993, 'queue_time': None, 'total_time': 0.112139075}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-635858c6-f820-4891-b83d-3145f0f17ce3-0', usage_metadata={'input_tokens': 77, 'output_tokens': 52, 'total_tokens': 129})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\", groq_api_key = groq_api_key)\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Tejha i am president\"),\n",
    "        AIMessage(content=\"Hello Tejha!\\n\\nIt's great to meet you. That's wonderful that you're the president!  \\n\\nWhat can I do for you today?\"),\n",
    "        HumanMessage(content=\"Hey whats my name and what so i do\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message History\n",
    "\n",
    "We can use a Message History class to wrap our model ad make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Lets see hoe to use this !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
